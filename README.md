
ManusAge â€” GenAI System for Ink Age Estimation &amp; Document Intelligence
ManusAge is a productionâ€‘grade GenAI system that performs ink age estimation, document intelligence, and contextâ€‘grounded reasoning using a hybrid of RAG, LLM orchestration, multimodal processing, and agentic workflows.
It is designed as an enterpriseâ€‘ready reference architecture for modern GenAI engineering.
---
âœ¨ Key Features
RAG Pipeline (Retrievalâ€‘Augmented Generation)
Uses PostgreSQL + pgvector for document embeddings and GPTâ€‘4oâ€‘mini for grounded answers.
Prompt Governance
Versioned prompts stored in Postgres with activation control.
Agentic Workflows
Summarization, evaluation (RAGAS + LLMâ€‘judge), and multimodal agents.
Multimodal Support
Text, audio, and image processing (future: ink age estimation model).
Memory Architecture
Postgres (primary vector store)
ChromaDB (shortâ€‘term memory)
MongoDB Atlas (longâ€‘term metadata)
Productionâ€‘Ready Backend
FastAPI, Docker, modular folder structure, and clean separation of concerns.
---
ğŸ“ Project Structure
manusage-backend/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â”œâ”€â”€ router.py
â”‚   â”‚   â”œâ”€â”€ pipeline.py
â”‚   â”‚   â”œâ”€â”€ retriever.py
â”‚   â”‚   â”œâ”€â”€ embeddings.py
â”‚   â”‚   â”œâ”€â”€ vector_store.py
â”‚   â”‚   â””â”€â”€ loader.py
â”‚   â”œâ”€â”€ prompt/
â”‚   â”‚   â”œâ”€â”€ seed_prompts.py
â”‚   â”‚   â””â”€â”€ prompt_loader.py
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ summarizer_agent.py
â”‚   â”‚   â”œâ”€â”€ evaluator_agent.py
â”‚   â”‚   â””â”€â”€ multimodal_agent.py
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ logger.py
â”‚
â”œâ”€â”€ db/
â”‚   â”œâ”€â”€ migrations/
â”‚   â”‚   â””â”€â”€ 001_init.sql
â”‚   â””â”€â”€ run_migrations.py
â”‚
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ MANUSAGE_SPEC.md

---
ğŸ§  Architecture Overview
Core Stack
FastAPI â€” backend API
PostgreSQL + pgvector â€” vector store
SentenceTransformers â€” embeddings
OpenAI GPTâ€‘4oâ€‘mini â€” LLM
LangChain / LangGraph / Smolagents â€” orchestration
ChromaDB â€” shortâ€‘term memory
MongoDB Atlas â€” longâ€‘term metadata
Data Flow
Documents are ingested â†’ chunked â†’ embedded â†’ stored in Postgres.
Query is embedded â†’ nearest neighbors retrieved.
Active system prompt loaded from Postgres.
GPTâ€‘4oâ€‘mini generates grounded response.
Agents optionally perform deeper analysis.
---
ğŸ—„ï¸ Database Schema
prompt_versions
Stores all prompt versions with activation flags.
documents
Stores raw text, embeddings, and metadata.
vector extension
pgvector enabled for similarity search.
---
ğŸš€ Getting Started
1. Install dependencies
pip install -r requirements.txt

2. Start PostgreSQL
Local:
brew services start postgresql

Or Docker:
docker run -d \
  --name manusage-db \
  -e POSTGRES_DB=postgres \
  -e POSTGRES_USER=maheswarareddyp \
  -p 5432:5432 \
  postgres:15

3. Run migrations
python db/migrations/run_migrations.py

4. Seed initial prompt
python app/prompt/seed_prompts.py

5. Start the API
uvicorn app.main:app --reload

---
ğŸ“¨ API Endpoints
POST /rag/ingest
Ingests and embeds documents.
POST /rag/query
Runs full RAG pipeline with GPTâ€‘4oâ€‘mini.
POST /agents/summarize
Summarizes long documents.
POST /agents/evaluate
Runs RAG evaluation (RAGAS + LLMâ€‘judge).
POST /agents/multimodal
Handles audio/image workflows.
---
ğŸ§ª Example Usage
Ingest documents
curl -X POST http://127.0.0.1:8000/rag/ingest

Query the system
curl -X POST http://127.0.0.1:8000/rag/query \
  -H "Content-Type: application/json" \
  -d '{"query": "How does ink age?", "prompt_name": "rag_system_prompt"}'

---
ğŸ“ˆ Roadmap
Phase 1 (Current)
RAG pipeline
Prompt governance
GPTâ€‘4oâ€‘mini integration
Phase 2
Audio transcription (Whisper)
Textâ€‘toâ€‘speech
Phase 3
Vision ingestion
Document image analysis
Phase 4
Custom ink age estimation model
Full multimodal agentic workflow
---
ğŸ“œ License
No License
